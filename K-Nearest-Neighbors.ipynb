{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7125e600-056e-4a7d-a7fe-9caffa414e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch: 1 to 500\n",
      "Processing batch: 501 to 1000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Path to folder containing the images\n",
    "image_folder = \"earth-terrain-height-and-segmentation-map-images\"\n",
    "\n",
    "# Define RGB-to-label mapping for segmentation map\n",
    "terrain_classes = {\n",
    "    (17, 141, 215): 0,  # Water\n",
    "    (225, 227, 155): 1,  # Grassland\n",
    "    (127, 173, 123): 2,  # Forest\n",
    "    (185, 122, 87): 3,  # Hills\n",
    "    (230, 200, 181): 4,  # Desert\n",
    "    (150, 150, 150): 5,  # Mountain\n",
    "    (193, 190, 175): 6   # Tundra\n",
    "}\n",
    "\n",
    "# Helper function to load and preprocess a single image set\n",
    "def load_and_preprocess(base_name, image_size=(64, 64)):\n",
    "    # Build file paths\n",
    "    terrain_path = os.path.join(image_folder, f'{base_name}_t.png')\n",
    "    height_path = os.path.join(image_folder, f'{base_name}_h.png')\n",
    "    segmentation_path = os.path.join(image_folder, f'{base_name}_i2.png')\n",
    "    \n",
    "    # Load images\n",
    "    terrain_image = imread(terrain_path)\n",
    "    height_image = imread(height_path)\n",
    "    segmentation_image = imread(segmentation_path)\n",
    "    \n",
    "    # Resize images\n",
    "    terrain_image = resize(terrain_image, image_size, anti_aliasing=True, preserve_range=True).astype('uint8')\n",
    "    height_image = resize(height_image, image_size, anti_aliasing=True, preserve_range=True).astype('uint16')\n",
    "    segmentation_image = resize(segmentation_image, image_size, anti_aliasing=True, preserve_range=True).astype('uint8')\n",
    "    \n",
    "    # Convert segmentation map to labels\n",
    "    labels = np.apply_along_axis(\n",
    "        lambda rgb: terrain_classes.get(tuple(rgb), -1), 2, segmentation_image\n",
    "    ).flatten()\n",
    "    \n",
    "    # Filter out invalid labels (-1)\n",
    "    valid_idx = labels != -1\n",
    "    \n",
    "    # Flatten and filter features\n",
    "    terrain_flat = terrain_image.reshape(-1, terrain_image.shape[-1])[valid_idx]\n",
    "    height_flat = height_image.flatten()[valid_idx]\n",
    "    features = np.hstack([terrain_flat, height_flat.reshape(-1, 1)])\n",
    "    \n",
    "    return features, labels[valid_idx]\n",
    "\n",
    "# Function to process images in batches\n",
    "def process_in_batches(batch_start, batch_end, image_size=(64, 64)):\n",
    "    batch_features = []\n",
    "    batch_labels = []\n",
    "    for i in range(batch_start, batch_end + 1):\n",
    "        base_name = f\"{str(i).zfill(4)}\"\n",
    "        try:\n",
    "            # Load and preprocess\n",
    "            features, labels = load_and_preprocess(base_name, image_size=image_size)\n",
    "            batch_features.append(features)\n",
    "            batch_labels.append(labels)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Image set {base_name} not found, skipping.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {base_name}: {e}\")\n",
    "    # Combine batch into numpy arrays\n",
    "    return np.vstack(batch_features), np.hstack(batch_labels)\n",
    "\n",
    "# Process images in manageable batches\n",
    "batch_size = 500  # Number of images per batch\n",
    "total_images = 1000  # Total number of images\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for batch_start in range(1, total_images + 1, batch_size):\n",
    "    batch_end = min(batch_start + batch_size - 1, total_images)\n",
    "    print(f\"Processing batch: {batch_start} to {batch_end}\")\n",
    "    batch_X, batch_y = process_in_batches(batch_start, batch_end)\n",
    "    X.append(batch_X)\n",
    "    y.append(batch_y)\n",
    "\n",
    "# Convert to single numpy arrays\n",
    "X = np.vstack(X)\n",
    "y = np.hstack(y)\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c927c92-03b7-4536-a978-9e7a562bc459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training K-Nearest Neighbors Classifier...\n",
      "KNN Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Water       1.00      1.00      1.00    216394\n",
      "   Grassland       0.99      0.99      0.99     78798\n",
      "      Forest       0.99      0.99      0.99    130847\n",
      "       Hills       1.00      0.99      0.99     52089\n",
      "      Desert       1.00      1.00      1.00     38999\n",
      "    Mountain       1.00      1.00      1.00     20652\n",
      "      Tundra       0.99      0.99      0.99     21534\n",
      "\n",
      "    accuracy                           1.00    559313\n",
      "   macro avg       0.99      1.00      1.00    559313\n",
      "weighted avg       1.00      1.00      1.00    559313\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Train K-Nearest Neighbors Classifier\n",
    "print(\"Training K-Nearest Neighbors Classifier...\")\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=5, weights='distance')  # Use distance-based weighting\n",
    "knn_classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = knn_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"KNN Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=[\n",
    "    \"Water\", \"Grassland\", \"Forest\", \"Hills\", \"Desert\", \"Mountain\", \"Tundra\"\n",
    "]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e786acd-aa96-424a-9cea-7d7f7cfa98e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[216204     33    128      0      5      0     24]\n",
      " [    23  78203    490     29     21      0     32]\n",
      " [    57    371 130160     99      0      1    159]\n",
      " [     0     21    128  51799     78     22     41]\n",
      " [     3     22      0     72  38845      0     57]\n",
      " [     0      0      1     24      0  20627      0]\n",
      " [     6      1    150     15     15      3  21344]]\n",
      "\n",
      "Accuracy: 1.00\n",
      "\n",
      "Micro Precision: 1.00\n",
      "Micro Recall: 1.00\n",
      "Micro F1-score: 1.00\n",
      "\n",
      "Macro Precision: 0.99\n",
      "Macro Recall: 1.00\n",
      "Macro F1-score: 1.00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print('\\nAccuracy: {:.2f}\\n'.format(accuracy_score(y_test, y_pred)))\n",
    "\n",
    "print('Micro Precision: {:.2f}'.format(precision_score(y_test, y_pred, average='micro')))\n",
    "print('Micro Recall: {:.2f}'.format(recall_score(y_test, y_pred, average='micro')))\n",
    "print('Micro F1-score: {:.2f}\\n'.format(f1_score(y_test, y_pred, average='micro')))\n",
    "\n",
    "print('Macro Precision: {:.2f}'.format(precision_score(y_test, y_pred, average='macro')))\n",
    "print('Macro Recall: {:.2f}'.format(recall_score(y_test, y_pred, average='macro')))\n",
    "print('Macro F1-score: {:.2f}\\n'.format(f1_score(y_test, y_pred, average='macro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a7db35-9bfe-4f49-87d9-501c61ea0c78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
