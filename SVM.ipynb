{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21de1dae-0ac2-43de-b38a-a9b1641b1994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch: 1 to 500\n",
      "Processing batch: 501 to 1000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Path to folder containing the images\n",
    "image_folder = \"earth-terrain-height-and-segmentation-map-images\"\n",
    "\n",
    "# Define RGB-to-label mapping for segmentation map\n",
    "terrain_classes = {\n",
    "    (17, 141, 215): 0,  # Water\n",
    "    (225, 227, 155): 1,  # Grassland\n",
    "    (127, 173, 123): 2,  # Forest\n",
    "    (185, 122, 87): 3,  # Hills\n",
    "    (230, 200, 181): 4,  # Desert\n",
    "    (150, 150, 150): 5,  # Mountain\n",
    "    (193, 190, 175): 6   # Tundra\n",
    "}\n",
    "\n",
    "# Helper function to load and preprocess a single image set\n",
    "def load_and_preprocess(base_name, image_size=(64, 64)):\n",
    "    # Build file paths\n",
    "    terrain_path = os.path.join(image_folder, f'{base_name}_t.png')\n",
    "    height_path = os.path.join(image_folder, f'{base_name}_h.png')\n",
    "    segmentation_path = os.path.join(image_folder, f'{base_name}_i2.png')\n",
    "    \n",
    "    # Load images\n",
    "    terrain_image = imread(terrain_path)\n",
    "    height_image = imread(height_path)\n",
    "    segmentation_image = imread(segmentation_path)\n",
    "    \n",
    "    # Resize images\n",
    "    terrain_image = resize(terrain_image, image_size, anti_aliasing=True, preserve_range=True).astype('uint8')\n",
    "    height_image = resize(height_image, image_size, anti_aliasing=True, preserve_range=True).astype('uint16')\n",
    "    segmentation_image = resize(segmentation_image, image_size, anti_aliasing=True, preserve_range=True).astype('uint8')\n",
    "    \n",
    "    # Convert segmentation map to labels\n",
    "    labels = np.apply_along_axis(\n",
    "        lambda rgb: terrain_classes.get(tuple(rgb), -1), 2, segmentation_image\n",
    "    ).flatten()\n",
    "    \n",
    "    # Filter out invalid labels (-1)\n",
    "    valid_idx = labels != -1\n",
    "    \n",
    "    # Flatten and filter features\n",
    "    terrain_flat = terrain_image.reshape(-1, terrain_image.shape[-1])[valid_idx]\n",
    "    height_flat = height_image.flatten()[valid_idx]\n",
    "    features = np.hstack([terrain_flat, height_flat.reshape(-1, 1)])\n",
    "    \n",
    "    return features, labels[valid_idx]\n",
    "\n",
    "# Function to process images in batches\n",
    "def process_in_batches(batch_start, batch_end, image_size=(64, 64)):\n",
    "    batch_features = []\n",
    "    batch_labels = []\n",
    "    for i in range(batch_start, batch_end + 1):\n",
    "        base_name = f\"{str(i).zfill(4)}\"\n",
    "        try:\n",
    "            # Load and preprocess\n",
    "            features, labels = load_and_preprocess(base_name, image_size=image_size)\n",
    "            batch_features.append(features)\n",
    "            batch_labels.append(labels)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Image set {base_name} not found, skipping.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {base_name}: {e}\")\n",
    "    # Combine batch into numpy arrays\n",
    "    return np.vstack(batch_features), np.hstack(batch_labels)\n",
    "\n",
    "# Process images in manageable batches\n",
    "batch_size = 500  # Number of images per batch\n",
    "total_images = 1000  # Total number of images\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for batch_start in range(1, total_images + 1, batch_size):\n",
    "    batch_end = min(batch_start + batch_size - 1, total_images)\n",
    "    print(f\"Processing batch: {batch_start} to {batch_end}\")\n",
    "    batch_X, batch_y = process_in_batches(batch_start, batch_end)\n",
    "    X.append(batch_X)\n",
    "    y.append(batch_y)\n",
    "\n",
    "# Convert to single numpy arrays\n",
    "X = np.vstack(X)\n",
    "y = np.hstack(y)\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b086e8a-7555-4f4e-85b2-e980b279ee2a",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1576445807.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[7], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    SVM svm_model = SVC(kernel='rbf', C=1.0, verbose=True, max_iter=1000)\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "print(\"Training SVM Model\")\n",
    "SVM svm_model = SVC(kernel='rbf', C=1.0, verbose=True, max_iter=1000)\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Step 5: Evaluate model\n",
    "print(\"Preparing to evaluate\")\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "print(\"Classification\")\n",
    "print(classification_report(y_test, y_pred, target_names=[\n",
    "    \"Water\", \"Grassland\", \"Forest\", \"Hills\", \"Desert\", \"Mountain\", \"Tundra\"\n",
    "]))\n",
    "\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print('\\nAccuracy: {:.2f}\\n'.format(accuracy_score(y_test, y_pred)))\n",
    "\n",
    "print('Micro Precision: {:.2f}'.format(precision_score(y_test, y_pred, average='micro')))\n",
    "print('Micro Recall: {:.2f}'.format(recall_score(y_test, y_pred, average='micro')))\n",
    "print('Micro F1-score: {:.2f}\\n'.format(f1_score(y_test, y_pred, average='micro')))\n",
    "\n",
    "print('Macro Precision: {:.2f}'.format(precision_score(y_test, y_pred, average='macro')))\n",
    "print('Macro Recall: {:.2f}'.format(recall_score(y_test, y_pred, average='macro')))\n",
    "print('Macro F1-score: {:.2f}\\n'.format(f1_score(y_test, y_pred, average='macro')))\n",
    "\n",
    "matrix = confusion_matrix(y_test, y_pred)\n",
    "class_accuracies = matrix.diagonal()/matrix.sum(axis=1)\n",
    "\n",
    "print(\"Per-Class Accuracy:\")\n",
    "for idx, class_name in enumerate([\"Water\", \"Grassland\", \"Forest\", \"Hills\", \"Desert\", \"Mountain\", \"Tundra\"]):\n",
    "    print(f\"{class_name}: {class_accuracies[idx]:.2f}\")\n",
    "\n",
    "\n",
    "\n",
    "# Function to decode label map to RGB for visualization\n",
    "def decode_segmentation_map(label_map, terrain_classes):\n",
    "    # Reverse the mapping dictionary\n",
    "    reverse_mapping = {v: k for k, v in terrain_classes.items()}\n",
    "    height, width = label_map.shape\n",
    "    rgb_map = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "\n",
    "    for label, rgb in reverse_mapping.items():\n",
    "        rgb_map[label_map == label] = rgb\n",
    "\n",
    "    return rgb_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf4c8a9-a85f-41f2-b6e2-2a45168e6b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show ground truth and predicted segmentation\n",
    "def visualize_segmentation(X_test, y_test, y_pred, index, terrain_classes, image_size=(64, 64)):\n",
    "    # Reshape labels to the original image shape\n",
    "    ground_truth = y_test[index * image_size[0] * image_size[1]:(index + 1) * image_size[0] * image_size[1]].reshape(image_size)\n",
    "    prediction = y_pred[index * image_size[0] * image_size[1]:(index + 1) * image_size[0] * image_size[1]].reshape(image_size)\n",
    "\n",
    "    # Decode to RGB maps for visualization\n",
    "    ground_truth_rgb = decode_segmentation_map(ground_truth, terrain_classes)\n",
    "    prediction_rgb = decode_segmentation_map(prediction, terrain_classes)\n",
    "\n",
    "    # Display images\n",
    "    plt.figure(figsize=(10, 5))\n",
    "\n",
    "    # Plot ground truth\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"Ground Truth\")\n",
    "    plt.imshow(ground_truth_rgb)\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Plot prediction\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"Prediction\")\n",
    "    plt.imshow(prediction_rgb)\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Call visualization function for the first test image\n",
    "print(\"Visualizing ground truth and predicted segmentation for the first test image.\")\n",
    "visualize_segmentation(X_test, y_test, y_pred, index=0, terrain_classes=terrain_classes, image_size=(64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17a57dd-6bac-4e54-8286-04707c1fb38d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
